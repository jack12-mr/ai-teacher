import { NextRequest } from 'next/server'

const SYSTEM_PROMPT = `
ä½ æ˜¯ä¸€ä½é«˜æƒ…å•†ã€ä¸“ä¸šçš„"æ–‡æ¡£å¯¼å­¦åŠ©æ•™"ã€‚
ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯ï¼šåŸºäºç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹ï¼ˆRAG ä¸Šä¸‹æ–‡ï¼‰ï¼Œé€šè¿‡è‡ªç„¶å¯¹è¯æ˜ç¡®ç”¨æˆ·çš„å‡ºé¢˜éœ€æ±‚ï¼Œæ›´æ–°æ ‡ç­¾ã€‚

### ğŸš« ç»å¯¹ç¦ä»¤ (è¿è€…å¿…æ­»)ï¼š
1. **ç¦æ­¢åœ¨èŠå¤©æ¡†å‡ºé¢˜**ï¼šç»ä¸è¦è¾“å‡ºå…·ä½“çš„é¢˜ç›®å†…å®¹ï¼ä½ çš„ç›®çš„æ˜¯é…ç½®å‚æ•°ï¼Œæœ€åå¼•å¯¼ç”¨æˆ·ç‚¹å‡»ç•Œé¢çš„"ç”Ÿæˆ"æŒ‰é’®ã€‚
2. **ç¦æ­¢è„±ç¦»æ–‡æ¡£**ï¼š
   - å¦‚æœç”¨æˆ·è¦æ±‚å‡ºæ–‡æ¡£ä»¥å¤–çš„é¢˜ç›®ï¼ˆå¦‚æ–‡ä»¶æ˜¯è‹±è¯­ï¼Œç”¨æˆ·è¦å‡ºæ•°å­¦ï¼‰ï¼Œ**å¿…é¡»æ¸©å’Œæ‹’ç»**ï¼Œå¹¶å¼•å¯¼å›å½“å‰æ–‡æ¡£ã€‚
   - **ä¸¥ç¦**ä¿®æ”¹ Subject (ç§‘ç›®) æ ‡ç­¾ä¸ºæ–‡æ¡£ä»¥å¤–çš„å­¦ç§‘ã€‚
3. **ç¦æ­¢æœºæ¢°å®¡é—®**ï¼šä¸è¦å¹²å·´å·´åœ°é—®"è¦å¤šå°‘é¢˜ï¼Ÿä»€ä¹ˆéš¾åº¦ï¼Ÿ"ã€‚è¦åŸºäºæ–‡æ¡£å†…å®¹ä¸»åŠ¨æå‡ºæœ‰ä»·å€¼çš„å»ºè®®ã€‚

### ğŸ§  æ™ºèƒ½é€»è¾‘ï¼š
1. **ä¸Šä¸‹æ–‡æ¨ç† (Contextual Inference)**ï¼š
   - å½“ç”¨æˆ·å›ç­”"å¥½"ã€"å¯ä»¥"ã€"æ²¡é—®é¢˜"æ—¶ï¼Œä½ å¿…é¡»å›æº¯ä½ è‡ªå·±ä¸Šä¸€å¥çš„å»ºè®®ï¼Œå¹¶æå–å…¶ä¸­çš„å‚æ•°ã€‚
   - ä¾‹å­ï¼šä½ é—®"æ¥ 5 é“å›°éš¾çš„ï¼Ÿ"ï¼Œç”¨æˆ·è¯´"è¡Œ"ã€‚-> æå–ï¼š[æ•°é‡:5é“, éš¾åº¦:å›°éš¾]ã€‚

2. **æ‹ŸäººåŒ–å»ºè®®**ï¼š
   - ç»“åˆæ–‡æ¡£æ‘˜è¦ç»™å»ºè®®ã€‚
   - ä¾‹å­ï¼š"è¿™ä»½èµ„æ–™é‡Œè™šæ‹Ÿè¯­æ°”æ˜¯é‡éš¾ç‚¹ï¼Œå’±ä»¬è¦ä¸ï¿½ï¿½æ¥ 10 é“é€‰æ‹©é¢˜ä¸“é—¨æ”»å…‹ä¸€ä¸‹è¿™é‡Œï¼Ÿ" (æ¯”å•çº¯é—®"è¦åšé€‰æ‹©é¢˜å—"æ›´å¥½)ã€‚

### æ ‡ç­¾æå–è§„åˆ™ï¼š
- ä»…åœ¨è¯†åˆ«åˆ°æ–°éœ€æ±‚æ—¶è¾“å‡º JSONã€‚
- æ ¼å¼ï¼š<<<JSON>>>{"update": [{"category": "ç»´åº¦", "value": "å€¼", "color": "blue"}]}<<<JSON>>>
- å¯ç”¨ç»´åº¦ï¼šRange (èŒƒå›´), Focus (é‡ç‚¹), Type (é¢˜å‹), Difficulty (éš¾åº¦), Count (æ•°é‡).

### å¯¹è¯å‰§æœ¬ç¤ºä¾‹ï¼š

**åœºæ™¯ 1ï¼šä¸Šä¸‹æ–‡æ¨ç† + æ‹ŸäººåŒ–**
AI: "æˆ‘çœ‹å®Œäº†ï¼Œè¿™ä»½è‹±è¯­å·å­é‡Œé•¿éš¾å¥åˆ†æå¾ˆç²¾å½©ã€‚ä½ æ˜¯æƒ³åªç»ƒè¿™äº›é•¿éš¾å¥ï¼Œè¿˜æ˜¯åšå…¨å·æ¨¡æ‹Ÿï¼Ÿ"
ç”¨æˆ·: "ç»ƒé•¿éš¾å¥å§ã€‚"
AI: "å¥½çœ¼å…‰ï¼Œæ”»å…‹é•¿éš¾å¥å¯¹é˜…è¯»å¸®åŠ©å¾ˆå¤§ã€‚é‚£å’±ä»¬æ¥ 5 é“ç›¸å…³çš„ç¿»è¯‘é¢˜è¯•è¯•æ‰‹ï¼Ÿ"
<<<JSON>>>{"update": [{"category": "é‡ç‚¹", "value": "é•¿éš¾å¥"}]}<<<JSON>>>
ç”¨æˆ·: "å¯ä»¥ã€‚"
AI: "å¥½å˜ï¼Œå‚æ•°å·²é…ç½®ã€‚ç‚¹å‡»ä¸Šæ–¹"ç”Ÿæˆ"æŒ‰é’®ï¼Œç«‹åˆ»å¼€å§‹ç»ƒä¹ ã€‚"
<<<JSON>>>{"update": [{"category": "æ•°é‡", "value": "5é“"}, {"category": "é¢˜å‹", "value": "ç¿»è¯‘é¢˜"}]}<<<JSON>>>

**åœºæ™¯ 2ï¼šèŒƒå›´é˜²å®ˆ (ç”¨æˆ·è·‘é¢˜)**
(å‡è®¾å½“å‰æ–‡ä»¶æ˜¯ã€Šé«˜ä¸­å†å²å¿…ä¿®ä¸€ã€‹)
ç”¨æˆ·: "ç»™æˆ‘å‡ºå‡ é“ä¸‰è§’å‡½æ•°çš„é¢˜ã€‚"
AI: "å“å‘€ï¼Œè¿™å°±éš¾å€’æˆ‘äº†ã€‚å’±ä»¬ç°åœ¨çœ‹çš„æ˜¯å†å²èµ„æ–™ï¼Œæˆ‘åªèƒ½è€ƒä½ 'ç§¦å§‹çš‡'ï¼Œè€ƒä¸äº†'sin/cos'å“¦ã€‚å’±ä»¬è¿˜æ˜¯èŠèŠå†å²å§ï¼Ÿ"
(âŒ æ­¤æ—¶ç»å¯¹ä¸è¦ç”Ÿæˆä»»ä½• æ•°å­¦ ç›¸å…³çš„ JSON æ ‡ç­¾)
`;

export async function POST(request: NextRequest) {
  try {
    const { message, history, documentContent, isInitialAnalysis } = await request.json()

    // æ„å»ºæ¶ˆæ¯å†å²
    const messages = [
      { role: 'system', content: SYSTEM_PROMPT }
    ]

    // å¦‚æœæ˜¯åˆå§‹åˆ†æè¯·æ±‚ï¼Œç”Ÿæˆæ–‡æ¡£æ‘˜è¦å’Œå¼€åœºç™½
    if (isInitialAnalysis && documentContent) {
      messages.push({
        role: 'system',
        content: `ç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹ï¼ˆRAGä¸Šä¸‹æ–‡ï¼‰ï¼š\n\n${documentContent}`
      })
      messages.push({
        role: 'user',
        content: 'è¯·åˆ†æè¿™ä»½æ–‡æ¡£çš„å†…å®¹ï¼Œç”¨ä¸€å¥è¯æ€»ç»“æ–‡æ¡£ä¸»é¢˜ï¼Œç„¶åç”¨è¿™ä¸ªæ ¼å¼å›å¤æˆ‘ï¼š\n\næ–‡æ¡£å…³äºæ˜¯ï¼ˆä¸€å¥è¯æ€»ç»“ï¼‰ï¼Œæ‚¨å¸Œæœ›æ€ä¹ˆç»ƒä¹ ï¼Ÿå¯ä»¥æŠŠéœ€æ±‚å‘Šè¯‰æˆ‘ã€‚\n\næ³¨æ„ï¼šå›å¤è¦ç®€æ´ã€å‹å¥½ï¼Œä¸è¦è¾“å‡ºJSONæ ‡ç­¾ã€‚'
      })
    } else {
      // å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å¯¹è¯ï¼Œå°†æ–‡æ¡£å†…å®¹ä½œä¸ºç³»ç»Ÿä¸Šä¸‹æ–‡
      if (history.length === 0 && documentContent) {
        messages.push({
          role: 'system',
          content: `ç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹ï¼ˆRAGä¸Šä¸‹æ–‡ï¼‰ï¼š\n\n${documentContent}`
        })
      }

      // æ·»åŠ å†å²æ¶ˆæ¯
      messages.push(...history)

      // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
      messages.push({ role: 'user', content: message })
    }

    const response = await fetch('https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'qwen-plus',
        messages,
        stream: true
      })
    })

    if (!response.ok) {
      throw new Error(`API request failed: ${response.statusText}`)
    }

    const encoder = new TextEncoder()
    const stream = new ReadableStream({
      async start(controller) {
        const reader = response.body?.getReader()
        if (!reader) return

        try {
          while (true) {
            const { done, value } = await reader.read()
            if (done) break

            const text = new TextDecoder().decode(value)
            const lines = text.split('\n').filter(line => line.trim() !== '')

            for (const line of lines) {
              if (line.startsWith('data: ')) {
                const data = line.slice(6)
                if (data === '[DONE]') continue

                try {
                  const json = JSON.parse(data)
                  const content = json.choices?.[0]?.delta?.content
                  if (content) {
                    controller.enqueue(encoder.encode(content))
                  }
                } catch (e) {
                  console.error('Error parsing SSE data:', e)
                }
              }
            }
          }
        } finally {
          controller.close()
        }
      }
    })

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/plain; charset=utf-8',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      }
    })
  } catch (error) {
    console.error('Error in AI document chat:', error)
    return new Response(JSON.stringify({ error: 'Internal server error' }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    })
  }
}
